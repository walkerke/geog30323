---
title: "Modules, packages, and EDA in Python"
author: GEOG 30323
date: February 1, 2022
output: 
  revealjs::revealjs_presentation: 
    theme: "white"
    transition: "none"
    highlight: "tango"
    center: TRUE
    fig_caption: TRUE
    
---

## Time for data!

<img src="img/data.jpg" style="width: 850px"><figcaption>Source: [bigdatapix.tumblr.com](http://bigdatapix.tumblr.com/)</figcaption>

---

### The data analysis process

<img src="http://r4ds.had.co.nz/diagrams/data-science.png" style="width: 800px"><figcaption>Source: Wickham and Grolemund, [_R for Data Science_](http://r4ds.had.co.nz/introduction.html)</figcaption>

---

### Exploratory data analysis

* "Detective work" to summarize and explore datasets

Includes: 

* Data acquisition and input
* Data cleaning and wrangling ("tidying")
* Data transformation and summarization
* Data visualization

Your core Python tools for EDA: NumPy, pandas, and seaborn/matplotlib

---

## Modules and packages

* _Module_: file containing variables, functions, etc. that can be _imported_ into a Python session with the `import` statement
* _Package_: directory of modules that perform similar tasks (e.g. data visualization, statistics, etc.)
* Thousands upon thousands of Python packages available - that do just about anything!

---

## Built-in packages

* Many packages are included in `stdlib`, the standard library that ships with Python
* Popular modules: `re` for regular expressions; `os` for operating system functions; `random` for random-number generation; and many more.  Full list: <https://docs.python.org/3/library/>

---

### The PyData ecosystem

<img src=img/pydata.PNG style="width: 700px"><figcaption>Source: [Jake VanderPlas, SciPy 2015 Keynote](https://speakerdeck.com/jakevdp/the-state-of-the-stack-scipy-2015-keynote)</figcaption>

---

### NumPy

* Extension to Python; the core Python package for numerical computing
* Standard import: `import numpy as np`
* Data structure: the NumPy __array__.  Sort of like a list - but with more methods, and can be multidimensional

```python
import numpy as np

y = np.array([[2, 4, 6, 8, 10, 12], 
             [1, 3, 5, 7, 9, 11], 
             [10, 12, 14, 18, 22, 14], 
             [9, 3, 3, 3, 3, 1]])
            
```

---

### Pandas

* Built on top of NumPy; adds support for table-like data structures in Python
* Standard import: `import pandas as pd`
* Sequences of data are stored as __Series__ objects, which collectively form __DataFrames__

```python
import pandas as pd

df = pd.DataFrame(y, columns = ['x' + str(num) for num in range(1, 7)])
```

---

## The pandas DataFrame

* Commonly, DataFrames are created by reading in external data, like CSV files
* Download link: <https://personal.tcu.edu/kylewalker/data/grad_rates.csv>

```python
# To read in CSV files, we use the pd.read_csv function 
grad = pd.read_csv("grad_rates.csv")
```

---

## Tutorial: working with external data in Colab

---

### The pandas DataFrame

* Each observation forms a __row__, defined by an __index__; attributes of those observations are found in the __columns__ of the DataFrame

<img src=img/df1.png>

* Columns are accessible as indices, e.g. `grad['rate']`, or as attributes of the data frame, e.g. `grad.rate`

---

### The Python namespace

* When you declare variables, define functions, import modules, etc., you are adding objects to the _Python namespace_
* To remove objects from the Python namespace, use the `del` statement


---

### Imports and the namespace 

* Imported modules can be referenced in multiple ways: 

```python
# All of these are equivalent

import pandas
pandas.read_csv("grad_rates.csv")

import pandas as pd
pd.read_csv("grad_rates.csv")

from pandas import *
read_csv("grad_rates.csv")
```

---

### Levels of measurement

* __Nominal__: qualitative, descriptive, categories
* __Ordinal__: ordering or ranking; however, no information about distance between ranks
* __Interval__: additive; no natural zero (zero is a meaningful value)
* __Ratio__: multiplicative; natural zero (zero means an absence of a value)

Make sure you know your column types (`dtypes`) and levels of measurement before doing analysis!

---

### Measures of central tendency

* __Mode__: the most typical value in a distribution
* __Median__: the "balancing point" in a distribution (50 percent of observations above and below)
* __Mean__: the arithmetic average of a distribution

The *mean* of a sample ($\overline{x}$) is calculated as follows:

$$\overline{x} = \dfrac{x_1 + x_2 + ... + x_n}{n}$$

where $n$ is the number of elements in the sample.  

---

### Measures of dispersion

* __Range__: difference between maximum and minimum values in a distribution
* __Interquartile range__: difference between the values at the 25 percent and 75 percent points in a distribution
* __Variance__ and __standard deviation__

---

## Standard deviation 

* Computed as the square root of the variance; denoted by $\sigma$.  
* Offers a standardized way to discuss the spread of a distribution.  For example, in a normally distributed sample: 
    * About 67 percent of the values will be within one standard deviation of the mean
    * About 95 percent of the values will be within two standard deviations of the mean
    * About 99 percent of the values will be within three standard deviations of the mean

---

### Descriptive statistics in pandas

* Descriptive stats are available in `pandas` as data frame methods, e.g. `grad.mean()`, `grad.std()`
* Calling `.describe()` will give you back a number of important descriptive stats at once

```python
grad.describe()
```
<img src=img/describe.png style="width: 25%">

---

## Exploratory visualization

* Often, when exploring a dataset, you'll want to use graphical representations of your data to help reveal insights/trends
* __Visualization__: Graphical representation of data

---

### Visualization in Python

* Core visualization package in Python: `matplotlib`
* `seaborn`: extension to `matplotlib` to make your graphics look nicer!  Standard import: `import seaborn as sns`.  


---

## Histograms

* __Histogram__: graphical representation of a frequency distribution
* Observations are organized into __bins__, and plotted with values along the x-axis and the number of observations in each bin along the y-axis
* __Normal distribution__: histogram is approximately symmetrical (a "bell curve")
* Histograms are built into `pandas`

---

### Example histogram (pandas method)

```python
import seaborn as sns
sns.set_style("darkgrid")

grad.rate.hist()
```
<img src=img/hist1.png style="width:600px">

---

### Example histogram (seaborn function)

```python
# Try the `bins` argument to modify the plot appearance
sns.histplot(data = grad, x = "rate")
```

<img src=img/hist2.png style="width:600px">

---

### Density plots

* Smooth representations of your data can be produced with __kernel density plots__
* Accessible from both `pandas` and `seaborn`

```python
sns.kdeplot(data = grad, x = "rate", shade = True)
```
<img src=img/kde.png>

---

### Box plots

* Also termed "box and whisker plots" - alternative way to show distribution of values graphically

```python
sns.boxplot(data = grad, y = "rate", color = "green")
```
<img src=img/boxplot.png>

---

### Anatomy of a box plot

<img src=img/anatomy.png>

* Dots beyond the whiskers: __outliers__

---

### Violin plots

* Combinations of box plots and kernel density plots

```python
sns.violinplot(data = grad, x = "rate", color = "cyan")
```

<img src=img/violin.png>



















<style>

.reveal section img {
  background:none; 
  border:none; 
  box-shadow:none;
  }
  
</style>
